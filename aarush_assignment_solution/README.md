ğŸ“„ README.md
# LiveKit Intelligent Interruption Handling

## ğŸ“Œ Overview

This project implements **context-aware interruption handling** for a real-time voice agent built using the LiveKit Agents framework.

The goal is to solve a common conversational UX problem in voice agents:  
**preventing false interruptions caused by passive listener acknowledgements** such as â€œyeahâ€, â€œokâ€, or â€œhmmâ€ while still allowing real interruption commands like â€œstopâ€ or â€œwaitâ€.

This solution strictly follows the constraints and evaluation criteria defined in the assignment.

---

## ğŸš¨ The Problem

LiveKitâ€™s default Voice Activity Detection (VAD) is intentionally fast but naive.

When the agent is speaking:
- Any detected user speech (even â€œyeahâ€) is treated as an interruption
- The agent abruptly stops speaking

This results in **unnatural and broken conversations**.

---

## ğŸ¯ Objective

Design and implement a **logic-level interruption filter** such that:

| User Input | Agent State | Expected Behavior |
|-----------|------------|------------------|
| â€œyeahâ€, â€œokâ€, â€œhmmâ€ | Speaking | **IGNORE** (agent continues seamlessly) |
| â€œstopâ€, â€œwaitâ€, â€œnoâ€ | Speaking | **INTERRUPT immediately** |
| â€œyeahâ€, â€œokâ€ | Silent | **RESPOND normally** |
| â€œyeah but waitâ€ | Speaking | **INTERRUPT** |

> âš ï¸ Partial solutions (pause â†’ resume, stutter, or hiccup) are **not acceptable**.

---

## ğŸ§  Core Insight

- **VAD is fast but does not understand intent**
- **STT is slower but semantically meaningful**

Therefore:
- We must **delay committing to an interruption**
- Until **speech-to-text confirms user intent**

---

## ğŸ—ï¸ Solution Architecture

The system introduces a **deterministic interruption gate** that sits between:



VAD â†’ STT â†’ Interruption Decision


### Key Signals Used

1. **Agent State**
   - Whether the agent is currently speaking or silent

2. **User Speech Detection**
   - VAD event indicates potential interruption attempt

3. **User Intent**
   - Final transcribed text from STT

---

## âš™ï¸ Interrupt Gate Logic

### Word Categories

#### Passive Acknowledgements (Soft Signals)
Examples:


yeah, ok, okay, hmm, uh-huh, right


#### Active Interruptions (Hard Signals)
Examples:


stop, wait, no, hold on, cancel


---

## ğŸ“Š Interrupt Scoring Mechanism

Each recognized word contributes to an **interrupt score**:

| Word Type | Score |
|----------|-------|
| Active interruption | +1.0 |
| Passive acknowledgement | -0.5 |

### Decision Rule



Final score > 0 â†’ Interrupt
Final score â‰¤ 0 â†’ Ignore


### Why this works

- A single strong command always wins
- Multiple filler words never cause interruption
- Mixed sentences are handled correctly
- Fully deterministic (no ML, no latency risk)

---

## ğŸ§ª Example Evaluations

| Input | Score | Result |
|------|------|-------|
| â€œyeahâ€ | -0.5 | IGNORE |
| â€œyeah okâ€ | -1.0 | IGNORE |
| â€œstopâ€ | +1.0 | INTERRUPT |
| â€œyeah waitâ€ | +0.5 | INTERRUPT |
| â€œok but stopâ€ | +0.5 | INTERRUPT |

---

## ğŸš« Explicit Constraints Followed

âœ” No modification to VAD kernel  
âœ” No reduction of VAD sensitivity  
âœ” No global disabling of interruptions  
âœ” No audible pause or resume artifacts  
âœ” Real-time safe and deterministic  

All logic is implemented **purely at the agent event-handling layer**.

---

## ğŸ§© Code Structure



aarush_assignment_solution/
â”‚
â”œâ”€â”€ agent.py # LiveKit agent + event wiring
â”œâ”€â”€ interrupt_gate.py # Core decision logic
â”œâ”€â”€ config.py # Ignore lists & scoring weights
â”œâ”€â”€ .env.example # Environment variable template
â””â”€â”€ README.md # This file


---

## ğŸ§  Why This Solution Is Correct

- **State-aware**: Same word behaves differently based on agent state
- **Race-condition safe**: VAD events are validated by STT
- **No stutter guarantee**: Agent audio is never stopped unless intent is confirmed
- **Production-grade logic**: Mirrors real-world conversational systems

---

## ğŸ“¹ Proof of Correctness

The submission includes:
- Agent ignoring â€œyeah / okâ€ while speaking
- Agent responding to â€œyeahâ€ when silent
- Agent immediately stopping on â€œstopâ€
- Handling of mixed inputs like â€œyeah waitâ€

---

## ğŸ“Œ Conclusion

This project demonstrates a robust, real-time, context-aware interruption handling system that improves conversational quality without compromising responsiveness or violating system constraints.

It addresses the **exact production 