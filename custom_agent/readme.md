ğŸš€ Interrupt-Aware Voice Agent (LiveKit Assignment)

This project implements a robust, real-time conversational voice agent using the LiveKit Agents SDK.
The agent correctly distinguishes between:

âœ” Backchannel words while the agent is speaking

(e.g., â€œyeahâ€, â€œokâ€, â€œrightâ€) â†’ ignored

âœ” Backchannel words while the agent is silent

(e.g., â€œyeahâ€, â€œokâ€) â†’ treated as valid answers

âœ” Explicit interrupt commands

(e.g., â€œstopâ€, â€œwaitâ€, â€œhold onâ€, â€œpauseâ€) â†’ immediately interrupts TTS

This behavior meets the core requirements of the assignment.

ğŸ“¦ Features Implemented
1. Backchannel Suppression

When the agent is speaking (state = speaking/thinking):

Words like â€œyeah, ok, hmm, rightâ€ are ignored.

Repeated backchannels trigger an interrupt after a threshold.

2. Backchannel Acceptance

When the agent is silent and has recently asked a question:

Same backchannel words are accepted as meaningful user replies.

3. Explicit Interrupt Detection

The agent immediately stops speaking when it hears interrupt keywords:
stop, wait, hold on, stop now, pause, cut, listen, what, why, hello...

4. Echo Suppression

Removes tiny transcriptions caused by TTS echo within 350ms.

5. Confidence-Aware Processing

Low-confidence single-token transcriptions are ignored.

6. Multilingual Turn-Detector (Silero + HuggingFace)

Automatically detects when the user starts or stops speaking.

ğŸ— Folder Structure (Minimal)
your-repo/
â”‚â”€â”€ test.py           # Your interrupt-aware agent implementation
â”‚â”€â”€ requirements.txt  # Full environment dependency list
â””â”€â”€ README.md         # This file

ğŸ”§ Installation
Create & activate a virtual environment
python -m venv .venv
.\.venv\Scripts\activate      # Windows

Install dependencies
pip install -r requirements.txt

ğŸ“¥ Download Required Model Files

The turn-detector plugin requires HuggingFace model files (model_q8.onnx, languages.json, etc.)

Run:

python test.py download-files


This automatically downloads required multilingual VAD / turn-detector models.

â–¶ï¸ Running the Agent

Start the real-time voice agent worker:

python test.py start


Your terminal will show:

starting worker...
registered worker...


This means your agent is alive and waiting for jobs from LiveKit.

ğŸ§ Testing in LiveKit Playground

Go to LiveKit Playground

Choose:

STT: deepgram/nova-3

LLM: openai/gpt-4o-mini

TTS: cartesia/sonic-2

Connect to your worker

ğŸ”‘ Required Environment Variables

Create a .env:

OPENAI_API_KEY=your-key
DEEPGRAM_API_KEY=your-key

LIVEKIT_URL=wss://your-project.livekit.cloud
LIVEKIT_API_KEY=xxx
LIVEKIT_API_SECRET=xxx

